{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers\n!pip install accelerate\n# To run the training on TPU, you will need to uncomment the followin line:\n# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n!apt install git-lfs\n!pip install -U huggingface_hub\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-06-11T19:02:09.562379Z","iopub.execute_input":"2022-06-11T19:02:09.562725Z","iopub.status.idle":"2022-06-11T19:02:58.037060Z","shell.execute_reply.started":"2022-06-11T19:02:09.562697Z","shell.execute_reply":"2022-06-11T19:02:58.036004Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning mBERT on SQuAD\nWe first have to fine-tune our mBERT model on the task of Question answering (QA).","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"squad\")\n#raw_datasets['train'] = raw_datasets['train'].shard(num_shards=40, index=0)\n#raw_datasets['validation'] = raw_datasets['validation'].shard(num_shards=10, index=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:45:56.102841Z","iopub.execute_input":"2022-06-11T20:45:56.103468Z","iopub.status.idle":"2022-06-11T20:45:56.724015Z","shell.execute_reply.started":"2022-06-11T20:45:56.103433Z","shell.execute_reply":"2022-06-11T20:45:56.723285Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing the training dataset","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:45:58.229458Z","iopub.execute_input":"2022-06-11T20:45:58.230100Z","iopub.status.idle":"2022-06-11T20:46:01.462914Z","shell.execute_reply.started":"2022-06-11T20:45:58.230061Z","shell.execute_reply":"2022-06-11T20:46:01.461866Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"max_length = 512\nstride = 128\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    context = examples[\"context\"]\n    \n    # Tokenize question and context together into one input,\n    # they will seperable with a special token between them.\n    # Tokenizer will also split context into multiple chuncks,\n    # if the max_length is exceeded.\n    inputs = tokenizer(\n        questions,\n        context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # offset_mapping is the result of the split into\n    # multiple chunks\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    # This step is required to see if an answer is inside\n    # the context chunks or not. It labels the multiple chunks\n    # generated by the tokenizer into either not having\n    # the answer, or where the answer is located\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:46:01.465018Z","iopub.execute_input":"2022-06-11T20:46:01.465412Z","iopub.status.idle":"2022-06-11T20:46:01.479457Z","shell.execute_reply.started":"2022-06-11T20:46:01.465372Z","shell.execute_reply":"2022-06-11T20:46:01.478574Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def preprocess_validation_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    context = examples[\"context\"]\n    \n    # It's the same thing as with the preprocess_training_examples\n    # tokenizer, but here \n    inputs = tokenizer(\n        questions,\n        context,\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        inputs[\"offset_mapping\"][i] = [\n            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n        ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:46:01.481094Z","iopub.execute_input":"2022-06-11T20:46:01.481464Z","iopub.status.idle":"2022-06-11T20:46:01.492634Z","shell.execute_reply.started":"2022-06-11T20:46:01.481426Z","shell.execute_reply":"2022-06-11T20:46:01.491857Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"].map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)\n\nvalidation_dataset = raw_datasets[\"validation\"].map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"validation\"].column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:46:01.495589Z","iopub.execute_input":"2022-06-11T20:46:01.495948Z","iopub.status.idle":"2022-06-11T20:46:12.897314Z","shell.execute_reply.started":"2022-06-11T20:46:01.495919Z","shell.execute_reply":"2022-06-11T20:46:12.896482Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import default_data_collator\n\ntrain_dataset.set_format(\"torch\")\nvalidation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\nvalidation_set.set_format(\"torch\")\n\ntrain_dataloader = DataLoader(\n    train_dataset,\n    shuffle=True,\n    collate_fn=default_data_collator,\n    batch_size=8,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Computing the metrics","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:11:03.671540Z","iopub.execute_input":"2022-06-11T21:11:03.671912Z","iopub.status.idle":"2022-06-11T21:11:06.926391Z","shell.execute_reply.started":"2022-06-11T21:11:03.671880Z","shell.execute_reply":"2022-06-11T21:11:06.925636Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"from torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:11:06.928251Z","iopub.execute_input":"2022-06-11T21:11:06.928639Z","iopub.status.idle":"2022-06-11T21:11:06.936968Z","shell.execute_reply.started":"2022-06-11T21:11:06.928598Z","shell.execute_reply":"2022-06-11T21:11:06.936045Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator(fp16=True)\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:11:06.938361Z","iopub.execute_input":"2022-06-11T21:11:06.938963Z","iopub.status.idle":"2022-06-11T21:11:07.131134Z","shell.execute_reply.started":"2022-06-11T21:11:06.938925Z","shell.execute_reply":"2022-06-11T21:11:07.130296Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_train_epochs = 2\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:11:07.133014Z","iopub.execute_input":"2022-06-11T21:11:07.133415Z","iopub.status.idle":"2022-06-11T21:11:07.139392Z","shell.execute_reply.started":"2022-06-11T21:11:07.133376Z","shell.execute_reply":"2022-06-11T21:11:07.138393Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport numpy as np\nimport torch\n\nprogress_bar = tqdm(range(num_training_steps))\n\noutput_dir = '/kaggle/working/model'\n\nfor epoch in range(num_train_epochs):\n    # Training\n    model.train()\n    for step, batch in enumerate(train_dataloader):\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T21:11:49.055630Z","iopub.execute_input":"2022-06-11T21:11:49.056001Z","iopub.status.idle":"2022-06-11T21:13:59.971217Z","shell.execute_reply.started":"2022-06-11T21:11:49.055970Z","shell.execute_reply":"2022-06-11T21:13:59.969870Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"accelerator.wait_for_everyone()\nunwrapped_model = accelerator.unwrap_model(model)\nunwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:48:52.562123Z","iopub.status.idle":"2022-06-11T20:48:52.562601Z","shell.execute_reply.started":"2022-06-11T20:48:52.562369Z","shell.execute_reply":"2022-06-11T20:48:52.562392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the fine-tuned model","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Replace this with your own checkpoint\nmodel_checkpoint = \"huggingface-course/bert-finetuned-squad\"\nquestion_answerer = pipeline(\"question-answering\", model=\"/kaggle/working/model\")\n\ncontext = \"\"\"\n? Transformers is backed by the three most popular deep learning libraries ? Jax, PyTorch and TensorFlow ? with a seamless integration\nbetween them. It's straightforward to train your models with one before loading them for inference with the other.\n\"\"\"\nquestion = \"What is backed by deep learning libraries?\"\nquestion_answerer(question=question, context=context)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:21:26.560574Z","iopub.execute_input":"2022-06-11T20:21:26.560950Z","iopub.status.idle":"2022-06-11T20:21:29.335409Z","shell.execute_reply.started":"2022-06-11T20:21:26.560917Z","shell.execute_reply":"2022-06-11T20:21:29.334601Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"## Validating using XQuAD","metadata":{}},{"cell_type":"code","source":"def get_predictions(dataset):\n    \n    predictions = []\n    for example in tqdm(dataset):\n        question = example['question']\n        context = example['context']\n        prediction = question_answerer(question=question, context=context)\n\n        predictions.append(prediction)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:24:53.487448Z","iopub.execute_input":"2022-06-11T20:24:53.487826Z","iopub.status.idle":"2022-06-11T20:24:53.492955Z","shell.execute_reply.started":"2022-06-11T20:24:53.487771Z","shell.execute_reply":"2022-06-11T20:24:53.491959Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Need to convert the variables so that they can be used by the evaluation.compute function\ndef convert_for_evaluation(predictions, examples):\n    ref = []\n    pred = []\n    for i, id in enumerate(examples['id']):\n        ref.append({\n            'answers': examples['answers'][i],\n            'id': examples['id'][i]\n        })\n        pred.append({\n            'prediction_text': predictions[i]['answer'],\n            'id': examples['id'][i]\n        })\n        \n    return pred, ref","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:24:53.719205Z","iopub.execute_input":"2022-06-11T20:24:53.720009Z","iopub.status.idle":"2022-06-11T20:24:53.726557Z","shell.execute_reply.started":"2022-06-11T20:24:53.719972Z","shell.execute_reply":"2022-06-11T20:24:53.725792Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom evaluate import load\n\nsquad_metric = load(\"squad\")\nresults = {}\n\nlanguages = [\"en\", \"fr\", \"es\", \"de\", \"el\", \"bg\", \"ru\", \"tr\", \"ar\", \"vi\", \"zh\"]\nfor lang in languages:\n    dataset = load_dataset(\"xquad\", 'xquad.' + lang)['validation']\n    \n    print('Running predictions for', lang)\n    predictions = get_predictions(dataset)\n\n    predictions, references = convert_for_evaluation(predictions, dataset) \n    res = squad_metric.compute(predictions=predictions, references=references)\n    \n    results[lang] = res","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:24:54.656456Z","iopub.execute_input":"2022-06-11T20:24:54.656819Z","iopub.status.idle":"2022-06-11T20:32:23.276844Z","shell.execute_reply.started":"2022-06-11T20:24:54.656776Z","shell.execute_reply":"2022-06-11T20:32:23.276040Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2022-06-11T20:34:04.860267Z","iopub.execute_input":"2022-06-11T20:34:04.860626Z","iopub.status.idle":"2022-06-11T20:34:04.866766Z","shell.execute_reply.started":"2022-06-11T20:34:04.860593Z","shell.execute_reply":"2022-06-11T20:34:04.865637Z"},"trusted":true},"execution_count":86,"outputs":[]}]}