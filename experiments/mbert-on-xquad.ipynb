{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-11T19:02:09.562725Z",
     "iopub.status.busy": "2022-06-11T19:02:09.562379Z",
     "iopub.status.idle": "2022-06-11T19:02:58.037060Z",
     "shell.execute_reply": "2022-06-11T19:02:58.036004Z",
     "shell.execute_reply.started": "2022-06-11T19:02:09.562697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Using cached pyarrow-8.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "Collecting dill<0.3.5\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Using cached fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./myenv/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.5.18.1-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv/lib/python3.10/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./myenv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: multidict, idna, frozenlist, yarl, urllib3, charset-normalizer, certifi, async-timeout, aiosignal, typing-extensions, tqdm, requests, pyyaml, pytz, numpy, fsspec, filelock, dill, aiohttp, xxhash, tokenizers, responses, regex, pyarrow, pandas, multiprocess, huggingface-hub, transformers, datasets\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 certifi-2022.5.18.1 charset-normalizer-2.0.12 datasets-2.2.2 dill-0.3.4 filelock-3.7.1 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 idna-3.3 multidict-6.0.2 multiprocess-0.70.12.2 numpy-1.22.4 pandas-1.4.2 pyarrow-8.0.0 pytz-2022.1 pyyaml-6.0 regex-2022.6.2 requests-2.28.0 responses-0.18.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.19.4 typing-extensions-4.2.0 urllib3-1.26.9 xxhash-3.0.0 yarl-1.7.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/mount/arbeitsdaten61/studenten3/advanced-ml/2022/maurerknuples/experiments/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.9.0-py3-none-any.whl (106 kB)\n",
      "Collecting torch>=1.4.0\n",
      "  Using cached torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: pyyaml in ./myenv/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./myenv/lib/python3.10/site-packages (from accelerate) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions in ./myenv/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (4.2.0)\n",
      "Installing collected packages: torch, accelerate\n",
      "Successfully installed accelerate-0.9.0 torch-1.11.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/mount/arbeitsdaten61/studenten3/advanced-ml/2022/maurerknuples/experiments/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in ./myenv/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (3.7.1)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (4.2.0)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.10/site-packages (from huggingface_hub) (2.28.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./myenv/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./myenv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.5.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/mount/arbeitsdaten61/studenten3/advanced-ml/2022/maurerknuples/experiments/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.1.1-py3-none-any.whl (68 kB)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./myenv/lib/python3.10/site-packages (from evaluate) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./myenv/lib/python3.10/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: datasets in ./myenv/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: responses<0.19 in ./myenv/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: xxhash in ./myenv/lib/python3.10/site-packages (from evaluate) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./myenv/lib/python3.10/site-packages (from evaluate) (2.28.0)\n",
      "Requirement already satisfied: multiprocess in ./myenv/lib/python3.10/site-packages (from evaluate) (0.70.12.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./myenv/lib/python3.10/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: dill in ./myenv/lib/python3.10/site-packages (from evaluate) (0.3.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./myenv/lib/python3.10/site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./myenv/lib/python3.10/site-packages (from evaluate) (2022.5.0)\n",
      "Requirement already satisfied: aiohttp in ./myenv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.2.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./myenv/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./myenv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv/lib/python3.10/site-packages (from aiohttp->fsspec[http]>=2021.05.0->evaluate) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./myenv/lib/python3.10/site-packages (from datasets->evaluate) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./myenv/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.10/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/mount/arbeitsdaten61/studenten3/advanced-ml/2022/maurerknuples/experiments/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers\n",
    "!pip install accelerate\n",
    "# To run the training on TPU, you will need to uncomment the followin line:\n",
    "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
    "!apt install git-lfs\n",
    "!pip install -U huggingface_hub\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package              Version\n",
      "-------------------- -----------\n",
      "accelerate           0.9.0\n",
      "aiohttp              3.8.1\n",
      "aiosignal            1.2.0\n",
      "argon2-cffi          21.3.0\n",
      "argon2-cffi-bindings 21.2.0\n",
      "asttokens            2.0.5\n",
      "async-timeout        4.0.2\n",
      "attrs                21.4.0\n",
      "backcall             0.2.0\n",
      "beautifulsoup4       4.11.1\n",
      "bleach               5.0.0\n",
      "certifi              2022.5.18.1\n",
      "cffi                 1.15.0\n",
      "charset-normalizer   2.0.12\n",
      "datasets             2.2.2\n",
      "debugpy              1.6.0\n",
      "decorator            5.1.1\n",
      "defusedxml           0.7.1\n",
      "dill                 0.3.4\n",
      "entrypoints          0.4\n",
      "evaluate             0.1.1\n",
      "executing            0.8.3\n",
      "fastjsonschema       2.15.3\n",
      "filelock             3.7.1\n",
      "frozenlist           1.3.0\n",
      "fsspec               2022.5.0\n",
      "huggingface-hub      0.7.0\n",
      "idna                 3.3\n",
      "ipykernel            6.14.0\n",
      "ipython              8.4.0\n",
      "ipython-genutils     0.2.0\n",
      "ipywidgets           7.7.0\n",
      "jedi                 0.18.1\n",
      "Jinja2               3.1.2\n",
      "jsonschema           4.6.0\n",
      "jupyter              1.0.0\n",
      "jupyter-client       7.3.4\n",
      "jupyter-console      6.4.3\n",
      "jupyter-core         4.10.0\n",
      "jupyterlab-pygments  0.2.2\n",
      "jupyterlab-widgets   1.1.0\n",
      "MarkupSafe           2.1.1\n",
      "matplotlib-inline    0.1.3\n",
      "mistune              0.8.4\n",
      "multidict            6.0.2\n",
      "multiprocess         0.70.12.2\n",
      "nbclient             0.6.4\n",
      "nbconvert            6.5.0\n",
      "nbformat             5.4.0\n",
      "nest-asyncio         1.5.5\n",
      "notebook             6.4.12\n",
      "numpy                1.22.4\n",
      "packaging            21.3\n",
      "pandas               1.4.2\n",
      "pandocfilters        1.5.0\n",
      "parso                0.8.3\n",
      "pexpect              4.8.0\n",
      "pickleshare          0.7.5\n",
      "pip                  21.2.3\n",
      "prometheus-client    0.14.1\n",
      "prompt-toolkit       3.0.29\n",
      "psutil               5.9.1\n",
      "ptyprocess           0.7.0\n",
      "pure-eval            0.2.2\n",
      "pyarrow              8.0.0\n",
      "pycparser            2.21\n",
      "Pygments             2.12.0\n",
      "pyparsing            3.0.9\n",
      "pyrsistent           0.18.1\n",
      "python-dateutil      2.8.2\n",
      "pytz                 2022.1\n",
      "PyYAML               6.0\n",
      "pyzmq                23.1.0\n",
      "qtconsole            5.3.1\n",
      "QtPy                 2.1.0\n",
      "regex                2022.6.2\n",
      "requests             2.28.0\n",
      "responses            0.18.0\n",
      "Send2Trash           1.8.0\n",
      "setuptools           57.4.0\n",
      "six                  1.16.0\n",
      "soupsieve            2.3.2.post1\n",
      "stack-data           0.2.0\n",
      "terminado            0.15.0\n",
      "tinycss2             1.1.1\n",
      "tokenizers           0.12.1\n",
      "torch                1.11.0\n",
      "tornado              6.1\n",
      "tqdm                 4.64.0\n",
      "traitlets            5.2.2.post1\n",
      "transformers         4.19.4\n",
      "typing_extensions    4.2.0\n",
      "urllib3              1.26.9\n",
      "wcwidth              0.2.5\n",
      "webencodings         0.5.1\n",
      "widgetsnbextension   3.6.0\n",
      "xxhash               3.0.0\n",
      "yarl                 1.7.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/mount/arbeitsdaten61/studenten3/advanced-ml/2022/maurerknuples/experiments/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning mBERT on SQuAD\n",
    "We first have to fine-tune our mBERT model on the task of Question answering (QA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:45:56.103468Z",
     "iopub.status.busy": "2022-06-11T20:45:56.102841Z",
     "iopub.status.idle": "2022-06-11T20:45:56.724015Z",
     "shell.execute_reply": "2022-06-11T20:45:56.723285Z",
     "shell.execute_reply.started": "2022-06-11T20:45:56.103433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/users1/knupleun/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac88ff0ddde493bbc669a4e5d9e5cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"squad\")\n",
    "#raw_datasets['train'] = raw_datasets['train'].shard(num_shards=40, index=0)\n",
    "#raw_datasets['validation'] = raw_datasets['validation'].shard(num_shards=10, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:45:58.230100Z",
     "iopub.status.busy": "2022-06-11T20:45:58.229458Z",
     "iopub.status.idle": "2022-06-11T20:46:01.462914Z",
     "shell.execute_reply": "2022-06-11T20:46:01.461866Z",
     "shell.execute_reply.started": "2022-06-11T20:45:58.230061Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:46:01.465412Z",
     "iopub.status.busy": "2022-06-11T20:46:01.465018Z",
     "iopub.status.idle": "2022-06-11T20:46:01.479457Z",
     "shell.execute_reply": "2022-06-11T20:46:01.478574Z",
     "shell.execute_reply.started": "2022-06-11T20:46:01.465372Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "stride = 128\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    context = examples[\"context\"]\n",
    "    \n",
    "    # Tokenize question and context together into one input,\n",
    "    # they will seperable with a special token between them.\n",
    "    # Tokenizer will also split context into multiple chuncks,\n",
    "    # if the max_length is exceeded.\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        context,\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # offset_mapping is the result of the split into\n",
    "    # multiple chunks\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # This step is required to see if an answer is inside\n",
    "    # the context chunks or not. It labels the multiple chunks\n",
    "    # generated by the tokenizer into either not having\n",
    "    # the answer, or where the answer is located\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:46:01.481464Z",
     "iopub.status.busy": "2022-06-11T20:46:01.481094Z",
     "iopub.status.idle": "2022-06-11T20:46:01.492634Z",
     "shell.execute_reply": "2022-06-11T20:46:01.491857Z",
     "shell.execute_reply.started": "2022-06-11T20:46:01.481426Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    context = examples[\"context\"]\n",
    "    \n",
    "    # It's the same thing as with the preprocess_training_examples\n",
    "    # tokenizer, but here \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        context,\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:46:01.495948Z",
     "iopub.status.busy": "2022-06-11T20:46:01.495589Z",
     "iopub.status.idle": "2022-06-11T20:46:12.897314Z",
     "shell.execute_reply": "2022-06-11T20:46:12.896482Z",
     "shell.execute_reply.started": "2022-06-11T20:46:01.495919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6921d615b94122bd0ed190fc22d3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe0299c07b043bdaed5bdfc183abab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "validation_set.set_format(\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=default_data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T21:11:03.671912Z",
     "iopub.status.busy": "2022-06-11T21:11:03.671540Z",
     "iopub.status.idle": "2022-06-11T21:11:06.926391Z",
     "shell.execute_reply": "2022-06-11T21:11:06.925636Z",
     "shell.execute_reply.started": "2022-06-11T21:11:03.671880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28391a541cc34b88a50de3aef7122a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T21:11:06.928639Z",
     "iopub.status.busy": "2022-06-11T21:11:06.928251Z",
     "iopub.status.idle": "2022-06-11T21:11:06.936968Z",
     "shell.execute_reply": "2022-06-11T21:11:06.936045Z",
     "shell.execute_reply.started": "2022-06-11T21:11:06.928598Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T21:11:06.938963Z",
     "iopub.status.busy": "2022-06-11T21:11:06.938361Z",
     "iopub.status.idle": "2022-06-11T21:11:07.131134Z",
     "shell.execute_reply": "2022-06-11T21:11:07.130296Z",
     "shell.execute_reply.started": "2022-06-11T21:11:06.938925Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(fp16=True)\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T21:11:07.133415Z",
     "iopub.status.busy": "2022-06-11T21:11:07.133014Z",
     "iopub.status.idle": "2022-06-11T21:11:07.139392Z",
     "shell.execute_reply": "2022-06-11T21:11:07.138393Z",
     "shell.execute_reply.started": "2022-06-11T21:11:07.133376Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 2\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T21:11:49.056001Z",
     "iopub.status.busy": "2022-06-11T21:11:49.055630Z",
     "iopub.status.idle": "2022-06-11T21:13:59.971217Z",
     "shell.execute_reply": "2022-06-11T21:13:59.969870Z",
     "shell.execute_reply.started": "2022-06-11T21:11:49.055970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f2a38cbd0d4b0e863ce2ab6d858f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "output_dir = './model'\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-11T20:48:52.562123Z",
     "iopub.status.idle": "2022-06-11T20:48:52.562601Z",
     "shell.execute_reply": "2022-06-11T20:48:52.562392Z",
     "shell.execute_reply.started": "2022-06-11T20:48:52.562369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.txt',\n",
       " './model/added_tokens.json',\n",
       " './model/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './model'\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:21:26.560950Z",
     "iopub.status.busy": "2022-06-11T20:21:26.560574Z",
     "iopub.status.idle": "2022-06-11T20:21:29.335409Z",
     "shell.execute_reply": "2022-06-11T20:21:29.334601Z",
     "shell.execute_reply.started": "2022-06-11T20:21:26.560917Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating using XQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:24:53.487826Z",
     "iopub.status.busy": "2022-06-11T20:24:53.487448Z",
     "iopub.status.idle": "2022-06-11T20:24:53.492955Z",
     "shell.execute_reply": "2022-06-11T20:24:53.491959Z",
     "shell.execute_reply.started": "2022-06-11T20:24:53.487771Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(dataset):\n",
    "    \n",
    "    predictions = []\n",
    "    for example in tqdm(dataset):\n",
    "        question = example['question']\n",
    "        context = example['context']\n",
    "        prediction = question_answerer(question=question, context=context)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:24:53.720009Z",
     "iopub.status.busy": "2022-06-11T20:24:53.719205Z",
     "iopub.status.idle": "2022-06-11T20:24:53.726557Z",
     "shell.execute_reply": "2022-06-11T20:24:53.725792Z",
     "shell.execute_reply.started": "2022-06-11T20:24:53.719972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Need to convert the variables so that they can be used by the evaluation.compute function\n",
    "def convert_for_evaluation(predictions, examples):\n",
    "    ref = []\n",
    "    pred = []\n",
    "    for i, id in enumerate(examples['id']):\n",
    "        ref.append({\n",
    "            'answers': examples['answers'][i],\n",
    "            'id': examples['id'][i]\n",
    "        })\n",
    "        pred.append({\n",
    "            'prediction_text': predictions[i]['answer'],\n",
    "            'id': examples['id'][i]\n",
    "        })\n",
    "        \n",
    "    return pred, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:24:54.656819Z",
     "iopub.status.busy": "2022-06-11T20:24:54.656456Z",
     "iopub.status.idle": "2022-06-11T20:32:23.276844Z",
     "shell.execute_reply": "2022-06-11T20:32:23.276040Z",
     "shell.execute_reply.started": "2022-06-11T20:24:54.656776Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.en/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667ccaf9188d49eaba92c64c8e91e458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for en\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845bb777065f433b9319e0bd0cf84a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e2ac43011e4645a35ce60ed66f1823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for es\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee50dc42ee604c0fb0d6ed76daf7599e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.de/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03c8882c93b43c7b49b77e7d31f2be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for de\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb718ba8fe504d75b6b1428b3f73aa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.el/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe74a41a44e54ee28556d65c0d20bfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for el\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e3a3f3ff0044929b9a6d5c50a1b8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.ru (download: 13.32 MiB, generated: 2.04 MiB, post-processed: Unknown size, total: 15.35 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51af627ed3a24e80805e564bcdec18d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c94fedf2fc14c3a8a122d2ef5acd979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fedf98087b44b3bc67ca2fe9f4cf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ru\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af2c463590d4327b506e73717d347a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.tr (download: 13.32 MiB, generated: 1.15 MiB, post-processed: Unknown size, total: 14.47 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.tr/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0151e2de8054306a542571fad60dcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570b14598e0d4cbab034a08d022b2e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.tr/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d9f43afb29451f9d58bbd013fe2d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for tr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7453b72336a344bdb255d33633af9e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.ar (download: 13.32 MiB, generated: 1.64 MiB, post-processed: Unknown size, total: 14.96 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a18f036cb204f45abd005004858a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf55b6b74c8441849573cb98aa3176a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c964dcf3aeae4998a4612cbf24a3e0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4925bd9022c940a8a875339309062fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.vi (download: 13.32 MiB, generated: 1.41 MiB, post-processed: Unknown size, total: 14.72 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.vi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a25c50177fc444b987b8244d49edda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ae013fe05c414fa87bb2b2252247a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.vi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a807c488244ad6996c74cb5a4175a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for vi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898213a778024e918311c8810d130e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.zh (download: 13.32 MiB, generated: 961.17 KiB, post-processed: Unknown size, total: 14.25 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.zh/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc22501762ab41abbc8523289a99382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73227e6afdbc488390ef9b1dfe2af996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.zh/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a6100f9ba0434ca8ff906da2eabe97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for zh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b13d2b21854f35b9b5f735066ef59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.hi (download: 13.32 MiB, generated: 2.56 MiB, post-processed: Unknown size, total: 15.87 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.hi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414c92da8814d4da080dbcd10c193f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe2bdfea6d44289a03fb82d78722d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.hi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef20c39a741436196b85bb02645cff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ba099eb78148fc83b2f33f955524ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.ro (download: 13.32 MiB, generated: 1.24 MiB, post-processed: Unknown size, total: 14.55 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ro/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fddc814c934864afb5174badcd3c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f906cf54ebb6448dab195d6ae86ec460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.ro/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed55781873b14f6485ef069045bacfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ro\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd4a559030647d48e33bf4a5957b2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xquad/xquad.th (download: 13.32 MiB, generated: 2.72 MiB, post-processed: Unknown size, total: 16.04 MiB) to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a967f4aca774791bb7fadc4d8d34acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4a3f47b2de484a8c6dc810bd260feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xquad downloaded and prepared to /home/users1/knupleun/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed027f66ba547f89513333406473624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for th\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4571f467fb0b49c69f8a1c9dcd1b0ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results = {}\n",
    "\n",
    "languages = [\"en\", \"es\", \"de\", \"el\", \"ru\", \"tr\", \"ar\", \"vi\", \"zh\", \"hi\", \"ro\", \"th\"]\n",
    "for lang in languages:\n",
    "    dataset = load_dataset(\"xquad\", 'xquad.' + lang)['validation']\n",
    "    \n",
    "    print('Running predictions for', lang)\n",
    "    predictions = get_predictions(dataset)\n",
    "\n",
    "    predictions, references = convert_for_evaluation(predictions, dataset) \n",
    "    res = squad_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    results[lang] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T20:34:04.860626Z",
     "iopub.status.busy": "2022-06-11T20:34:04.860267Z",
     "iopub.status.idle": "2022-06-11T20:34:04.866766Z",
     "shell.execute_reply": "2022-06-11T20:34:04.865637Z",
     "shell.execute_reply.started": "2022-06-11T20:34:04.860593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'exact_match': 72.52100840336135, 'f1': 84.63381393318429},\n",
       " 'es': {'exact_match': 56.134453781512605, 'f1': 75.03973047509686},\n",
       " 'de': {'exact_match': 55.378151260504204, 'f1': 71.83606003345174},\n",
       " 'el': {'exact_match': 44.621848739495796, 'f1': 60.00397764273023},\n",
       " 'ru': {'exact_match': 52.6890756302521, 'f1': 69.68082354979049},\n",
       " 'tr': {'exact_match': 39.2436974789916, 'f1': 53.94504953241661},\n",
       " 'ar': {'exact_match': 44.53781512605042, 'f1': 61.05297599918095},\n",
       " 'vi': {'exact_match': 49.075630252100844, 'f1': 68.70494098227722},\n",
       " 'zh': {'exact_match': 48.65546218487395, 'f1': 57.28618113912226},\n",
       " 'hi': {'exact_match': 43.109243697478995, 'f1': 58.05880441958488},\n",
       " 'ro': {'exact_match': 58.99159663865546, 'f1': 72.45369131036566},\n",
       " 'th': {'exact_match': 36.134453781512605, 'f1': 44.38268640789652}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
