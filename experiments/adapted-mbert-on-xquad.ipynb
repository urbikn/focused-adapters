{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Fine-tuning mBERT on SQuAD with task adapters"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:45:56.103468Z","iopub.status.busy":"2022-06-11T20:45:56.102841Z","iopub.status.idle":"2022-06-11T20:45:56.724015Z","shell.execute_reply":"2022-06-11T20:45:56.723285Z","shell.execute_reply.started":"2022-06-11T20:45:56.103433Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Reusing dataset squad (/home/mmm/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n","100%|██████████| 2/2 [00:00<00:00, 746.58it/s]\n"]}],"source":["from datasets import load_dataset\n","\n","raw_datasets = load_dataset(\"squad\")\n","#raw_datasets['train'] = raw_datasets['train'].shard(num_shards=40, index=0)\n","#raw_datasets['validation'] = raw_datasets['validation'].shard(num_shards=10, index=0)"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocessing the training dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:45:58.230100Z","iopub.status.busy":"2022-06-11T20:45:58.229458Z","iopub.status.idle":"2022-06-11T20:46:01.462914Z","shell.execute_reply":"2022-06-11T20:46:01.461866Z","shell.execute_reply.started":"2022-06-11T20:45:58.230061Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","model_checkpoint = \"bert-base-multilingual-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:46:01.465412Z","iopub.status.busy":"2022-06-11T20:46:01.465018Z","iopub.status.idle":"2022-06-11T20:46:01.479457Z","shell.execute_reply":"2022-06-11T20:46:01.478574Z","shell.execute_reply.started":"2022-06-11T20:46:01.465372Z"},"trusted":true},"outputs":[],"source":["max_length = 512\n","stride = 128\n","\n","def preprocess_training_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    context = examples[\"context\"]\n","    \n","    # Tokenize question and context together into one input,\n","    # they will seperable with a special token between them.\n","    # Tokenizer will also split context into multiple chuncks,\n","    # if the max_length is exceeded.\n","    inputs = tokenizer(\n","        questions,\n","        context,\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # offset_mapping is the result of the split into\n","    # multiple chunks\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    # This step is required to see if an answer is inside\n","    # the context chunks or not. It labels the multiple chunks\n","    # generated by the tokenizer into either not having\n","    # the answer, or where the answer is located\n","    for i, offset in enumerate(offset_mapping):\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context, label is (0, 0)\n","        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:46:01.481464Z","iopub.status.busy":"2022-06-11T20:46:01.481094Z","iopub.status.idle":"2022-06-11T20:46:01.492634Z","shell.execute_reply":"2022-06-11T20:46:01.491857Z","shell.execute_reply.started":"2022-06-11T20:46:01.481426Z"},"trusted":true},"outputs":[],"source":["def preprocess_validation_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    context = examples[\"context\"]\n","    \n","    # It's the same thing as with the preprocess_training_examples\n","    # tokenizer, but here \n","    inputs = tokenizer(\n","        questions,\n","        context,\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    example_ids = []\n","\n","    for i in range(len(inputs[\"input_ids\"])):\n","        sample_idx = sample_map[i]\n","        example_ids.append(examples[\"id\"][sample_idx])\n","\n","        sequence_ids = inputs.sequence_ids(i)\n","        offset = inputs[\"offset_mapping\"][i]\n","        inputs[\"offset_mapping\"][i] = [\n","            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n","        ]\n","\n","    inputs[\"example_id\"] = example_ids\n","    return inputs"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:46:01.495948Z","iopub.status.busy":"2022-06-11T20:46:01.495589Z","iopub.status.idle":"2022-06-11T20:46:12.897314Z","shell.execute_reply":"2022-06-11T20:46:12.896482Z","shell.execute_reply.started":"2022-06-11T20:46:01.495919Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading cached processed dataset at /home/mmm/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-92828b7751ed853e.arrow\n","Loading cached processed dataset at /home/mmm/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-6e87d240902843c3.arrow\n"]}],"source":["train_dataset = raw_datasets[\"train\"].map(\n","    preprocess_training_examples,\n","    batched=True,\n","    remove_columns=raw_datasets[\"train\"].column_names,\n",")\n","\n","validation_dataset = raw_datasets[\"validation\"].map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=raw_datasets[\"validation\"].column_names,\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from transformers import default_data_collator\n","\n","train_dataset.set_format(\"torch\")\n","validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n","validation_set.set_format(\"torch\")\n","\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    shuffle=True,\n","    collate_fn=default_data_collator,\n","    batch_size=8,\n",")\n","\n","validation_dataloader = DataLoader(\n","    validation_dataset,\n","    shuffle=True,\n","    collate_fn=default_data_collator,\n","    batch_size=8,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Computing the metrics"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T21:11:03.671912Z","iopub.status.busy":"2022-06-11T21:11:03.671540Z","iopub.status.idle":"2022-06-11T21:11:06.926391Z","shell.execute_reply":"2022-06-11T21:11:06.925636Z","shell.execute_reply.started":"2022-06-11T21:11:03.671880Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForQuestionAnswering\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["adapter_name = 'squad_adapter'\n","# model.add_adapter(adapter_name)\n","model.load_adapter(\"./adapter_qa_2ep/\")\n","model.train_adapter(adapter_name)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BertForQuestionAnswering(\n","  (shared_parameters): ModuleDict()\n","  (bert): BertModel(\n","    (shared_parameters): ModuleDict()\n","    (invertible_adapters): ModuleDict()\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (squad_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=48, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","      )\n","    )\n","    (prefix_tuning): PrefixTuningPool(\n","      (prefix_tunings): ModuleDict()\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model.set_active_adapters(adapter_name)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["batch_size = 8"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from transformers import TrainingArguments"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    f\"{model_name}-adapter-squad\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=1e-4,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=2,\n","    weight_decay=0.01\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from transformers import AdapterTrainer"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["trainer = AdapterTrainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    data_collator=default_data_collator,\n","    tokenizer=tokenizer\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 87767\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 21942\n","  2%|▏         | 500/21942 [04:14<3:01:41,  1.97it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8772, 'learning_rate': 0.0, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 1000/21942 [08:16<2:45:58,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-1000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9081, 'learning_rate': 0.0, 'epoch': 0.09}\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 1500/21942 [12:14<2:42:01,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-1500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-1500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8919, 'learning_rate': 0.0, 'epoch': 0.14}\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 2000/21942 [16:13<2:38:24,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-2000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8707, 'learning_rate': 0.0, 'epoch': 0.18}\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█▏        | 2500/21942 [20:11<2:34:11,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-2500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-2500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9196, 'learning_rate': 0.0, 'epoch': 0.23}\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▎        | 3000/21942 [24:09<2:30:08,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-3000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8977, 'learning_rate': 0.0, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 3500/21942 [28:08<2:26:30,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-3500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-3500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9183, 'learning_rate': 0.0, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 4000/21942 [32:06<2:22:24,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-4000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9135, 'learning_rate': 0.0, 'epoch': 0.36}\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 4500/21942 [36:04<2:18:30,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-4500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-4500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8948, 'learning_rate': 0.0, 'epoch': 0.41}\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 5000/21942 [40:03<2:14:33,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-5000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8836, 'learning_rate': 0.0, 'epoch': 0.46}\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 5500/21942 [44:01<2:10:37,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-5500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-5500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8705, 'learning_rate': 0.0, 'epoch': 0.5}\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 6000/21942 [48:10<2:14:51,  1.97it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-6000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.888, 'learning_rate': 0.0, 'epoch': 0.55}\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|██▉       | 6500/21942 [52:19<2:02:32,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-6500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-6500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8851, 'learning_rate': 0.0, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 7000/21942 [56:17<1:58:28,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-7000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8967, 'learning_rate': 0.0, 'epoch': 0.64}\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 7500/21942 [1:00:15<1:54:33,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-7500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-7500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8921, 'learning_rate': 0.0, 'epoch': 0.68}\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▋      | 8000/21942 [1:04:13<1:50:38,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-8000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8804, 'learning_rate': 0.0, 'epoch': 0.73}\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▊      | 8500/21942 [1:08:12<1:46:35,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-8500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-8500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9017, 'learning_rate': 0.0, 'epoch': 0.77}\n"]},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 9000/21942 [1:12:10<1:42:39,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-9000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9061, 'learning_rate': 0.0, 'epoch': 0.82}\n"]},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 9500/21942 [1:16:08<1:38:43,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-9500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-9500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8834, 'learning_rate': 0.0, 'epoch': 0.87}\n"]},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 10000/21942 [1:20:07<1:34:43,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-10000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9426, 'learning_rate': 0.0, 'epoch': 0.91}\n"]},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 10500/21942 [1:24:05<1:30:44,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-10500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-10500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8869, 'learning_rate': 0.0, 'epoch': 0.96}\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 10971/21942 [1:27:49<1:23:37,  2.19it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Evaluation *****\n","  Num examples = 10634\n","  Batch size = 8\n","\n"," 50%|█████     | 10971/21942 [1:32:41<1:23:37,  2.19it/s]"]},{"name":"stdout","output_type":"stream","text":["{'eval_runtime': 292.0483, 'eval_samples_per_second': 36.412, 'eval_steps_per_second': 4.554, 'epoch': 1.0}\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 11000/21942 [1:32:55<1:27:32,  2.08it/s]  Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-11000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9039, 'learning_rate': 0.0, 'epoch': 1.0}\n"]},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 11500/21942 [1:36:54<1:22:49,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-11500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-11500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9155, 'learning_rate': 0.0, 'epoch': 1.05}\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▍    | 12000/21942 [1:40:52<1:18:51,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-12000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9322, 'learning_rate': 0.0, 'epoch': 1.09}\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 12500/21942 [1:44:50<1:14:58,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-12500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-12500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8965, 'learning_rate': 0.0, 'epoch': 1.14}\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 13000/21942 [1:48:49<1:10:54,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-13000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9007, 'learning_rate': 0.0, 'epoch': 1.18}\n"]},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 13500/21942 [1:52:47<1:06:58,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-13500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-13500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.898, 'learning_rate': 0.0, 'epoch': 1.23}\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|██████▍   | 14000/21942 [1:56:45<1:03:02,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-14000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9053, 'learning_rate': 0.0, 'epoch': 1.28}\n"]},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 14500/21942 [2:00:44<59:03,  2.10it/s]  Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-14500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-14500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8998, 'learning_rate': 0.0, 'epoch': 1.32}\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 15000/21942 [2:04:42<55:03,  2.10it/s]  Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-15000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8896, 'learning_rate': 0.0, 'epoch': 1.37}\n"]},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 15500/21942 [2:08:40<51:07,  2.10it/s]  Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-15500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-15500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8678, 'learning_rate': 0.0, 'epoch': 1.41}\n"]},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 16000/21942 [2:12:39<47:10,  2.10it/s]  Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-16000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9083, 'learning_rate': 0.0, 'epoch': 1.46}\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 16500/21942 [2:16:37<43:10,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-16500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-16500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8935, 'learning_rate': 0.0, 'epoch': 1.5}\n"]},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 17000/21942 [2:20:35<39:15,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-17000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.871, 'learning_rate': 0.0, 'epoch': 1.55}\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 17500/21942 [2:24:34<35:14,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-17500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-17500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.895, 'learning_rate': 0.0, 'epoch': 1.6}\n"]},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 18000/21942 [2:28:32<31:17,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-18000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8825, 'learning_rate': 0.0, 'epoch': 1.64}\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▍ | 18500/21942 [2:32:30<27:19,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-18500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-18500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8986, 'learning_rate': 0.0, 'epoch': 1.69}\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 19000/21942 [2:36:28<23:20,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-19000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9006, 'learning_rate': 0.0, 'epoch': 1.73}\n"]},{"name":"stderr","output_type":"stream","text":[" 89%|████████▉ | 19500/21942 [2:40:27<19:22,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-19500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-19500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8949, 'learning_rate': 0.0, 'epoch': 1.78}\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 20000/21942 [2:44:25<15:24,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-20000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8945, 'learning_rate': 0.0, 'epoch': 1.82}\n"]},{"name":"stderr","output_type":"stream","text":[" 93%|█████████▎| 20500/21942 [2:48:23<11:27,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-20500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-20500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8483, 'learning_rate': 0.0, 'epoch': 1.87}\n"]},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 21000/21942 [2:52:22<07:28,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-21000\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21000/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.8763, 'learning_rate': 0.0, 'epoch': 1.91}\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 21500/21942 [2:56:20<03:30,  2.10it/s]Saving model checkpoint to bert-base-multilingual-cased-adapter-squad/checkpoint-21500\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/squad_adapter/adapter_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/squad_adapter/pytorch_adapter.bin\n","Configuration saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/squad_adapter/head_config.json\n","Module weights saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/squad_adapter/pytorch_model_head.bin\n","tokenizer config file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-adapter-squad/checkpoint-21500/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.9005, 'learning_rate': 0.0, 'epoch': 1.96}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 21942/21942 [2:59:51<00:00,  2.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Evaluation *****\n","  Num examples = 10634\n","  Batch size = 8\n","\n","100%|██████████| 21942/21942 [3:04:43<00:00,  2.18it/s]\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","100%|██████████| 21942/21942 [3:04:43<00:00,  1.98it/s]"]},{"name":"stdout","output_type":"stream","text":["{'eval_runtime': 291.9771, 'eval_samples_per_second': 36.421, 'eval_steps_per_second': 4.555, 'epoch': 2.0}\n","{'train_runtime': 11083.1824, 'train_samples_per_second': 15.838, 'train_steps_per_second': 1.98, 'train_loss': 0.8951242328852771, 'epoch': 2.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["TrainOutput(global_step=21942, training_loss=0.8951242328852771, metrics={'train_runtime': 11083.1824, 'train_samples_per_second': 15.838, 'train_steps_per_second': 1.98, 'train_loss': 0.8951242328852771, 'epoch': 2.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in ./adapter_qa_6ep/adapter_config.json\n","Module weights saved in ./adapter_qa_6ep/pytorch_adapter.bin\n","Configuration saved in ./adapter_qa_6ep/head_config.json\n","Module weights saved in ./adapter_qa_6ep/pytorch_model_head.bin\n"]}],"source":["model.save_adapter(\"./adapter_qa_6ep/\", adapter_name)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["adapter_checkpoint = \"./adapter_qa_6ep/\"\n","adapter_name = 'squad_adapter'\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n","model.load_adapter(adapter_checkpoint)\n","model.set_active_adapters(adapter_name)"]},{"cell_type":"markdown","metadata":{},"source":["## Testing the fine-tuned model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:21:26.560950Z","iopub.status.busy":"2022-06-11T20:21:26.560574Z","iopub.status.idle":"2022-06-11T20:21:29.335409Z","shell.execute_reply":"2022-06-11T20:21:29.334601Z","shell.execute_reply.started":"2022-06-11T20:21:26.560917Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'score': 0.7918965220451355, 'start': 3, 'end': 15, 'answer': 'Transformers'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline\n","\n","# Replace this with your own checkpoint\n","# model_checkpoint = adapter_checkpoint\n","question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n","\n","context = \"\"\"\n","? Transformers is backed by the three most popular deep learning libraries ? Jax, PyTorch and TensorFlow ? with a seamless integration\n","between them. It's straightforward to train your models with one before loading them for inference with the other.\n","\"\"\"\n","question = \"What is backed by deep learning libraries?\"\n","question_answerer(question=question, context=context)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Validating using XQuAD"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:24:53.487826Z","iopub.status.busy":"2022-06-11T20:24:53.487448Z","iopub.status.idle":"2022-06-11T20:24:53.492955Z","shell.execute_reply":"2022-06-11T20:24:53.491959Z","shell.execute_reply.started":"2022-06-11T20:24:53.487771Z"},"trusted":true},"outputs":[],"source":["def get_predictions(dataset):\n","    \n","    predictions = []\n","    for example in tqdm(dataset):\n","        question = example['question']\n","        context = example['context']\n","        prediction = question_answerer(question=question, context=context)\n","\n","        predictions.append(prediction)\n","    \n","    return predictions"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:24:53.720009Z","iopub.status.busy":"2022-06-11T20:24:53.719205Z","iopub.status.idle":"2022-06-11T20:24:53.726557Z","shell.execute_reply":"2022-06-11T20:24:53.725792Z","shell.execute_reply.started":"2022-06-11T20:24:53.719972Z"},"trusted":true},"outputs":[],"source":["# Need to convert the variables so that they can be used by the evaluation.compute function\n","def convert_for_evaluation(predictions, examples):\n","    ref = []\n","    pred = []\n","    for i, id in enumerate(examples['id']):\n","        ref.append({\n","            'answers': examples['answers'][i],\n","            'id': examples['id'][i]\n","        })\n","        pred.append({\n","            'prediction_text': predictions[i]['answer'],\n","            'id': examples['id'][i]\n","        })\n","        \n","    return pred, ref"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:24:54.656819Z","iopub.status.busy":"2022-06-11T20:24:54.656456Z","iopub.status.idle":"2022-06-11T20:32:23.276844Z","shell.execute_reply":"2022-06-11T20:32:23.276040Z","shell.execute_reply.started":"2022-06-11T20:24:54.656776Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.en/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 778.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for en\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▎      | 400/1190 [01:12<04:01,  3.27it/s]/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:708: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  tensor = as_tensor(value)\n","/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  p_mask = np.asarray(\n","100%|██████████| 1190/1190 [04:01<00:00,  4.92it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 623.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for es\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:17<00:00,  4.63it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.de/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 832.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for de\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [03:58<00:00,  4.99it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.el/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 762.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for el\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [08:01<00:00,  2.47it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 780.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for ru\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:48<00:00,  4.13it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.tr/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 732.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for tr\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:28<00:00,  4.44it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 580.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for ar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [05:43<00:00,  3.47it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.vi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 731.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for vi\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:09<00:00,  4.77it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.zh/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 699.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for zh\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:33<00:00,  4.35it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.hi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 741.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for hi\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [06:07<00:00,  3.24it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ro/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 765.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for ro\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [04:54<00:00,  4.04it/s]\n","Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n","100%|██████████| 1/1 [00:00<00:00, 734.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Running predictions for th\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1190/1190 [11:55<00:00,  1.66it/s]\n"]}],"source":["from datasets import load_dataset\n","import evaluate\n","\n","squad_metric = evaluate.load(\"squad\")\n","results = {}\n","\n","languages = [\"en\", \"es\", \"de\", \"el\", \"ru\", \"tr\", \"ar\", \"vi\", \"zh\", \"hi\", \"ro\", \"th\"]\n","for lang in languages:\n","    dataset = load_dataset(\"xquad\", 'xquad.' + lang)['validation']\n","    \n","    print('Running predictions for', lang)\n","    predictions = get_predictions(dataset)\n","\n","    predictions, references = convert_for_evaluation(predictions, dataset) \n","    res = squad_metric.compute(predictions=predictions, references=references)\n","    \n","    results[lang] = res"]},{"cell_type":"markdown","metadata":{},"source":["#### Results for Adapter after 6 Epochs of Training"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["{'en': {'exact_match': 70.67226890756302, 'f1': 82.5247970156043},\n"," 'es': {'exact_match': 55.04201680672269, 'f1': 73.57229446436855},\n"," 'de': {'exact_match': 56.30252100840336, 'f1': 71.14567157643546},\n"," 'el': {'exact_match': 43.109243697478995, 'f1': 56.378219636212144},\n"," 'ru': {'exact_match': 52.52100840336134, 'f1': 68.55032134571113},\n"," 'tr': {'exact_match': 36.134453781512605, 'f1': 52.10511404616692},\n"," 'ar': {'exact_match': 43.69747899159664, 'f1': 60.071794671501856},\n"," 'vi': {'exact_match': 47.64705882352941, 'f1': 68.2884260182452},\n"," 'zh': {'exact_match': 47.64705882352941, 'f1': 56.072629051620595},\n"," 'hi': {'exact_match': 40.08403361344538, 'f1': 53.37206132647197},\n"," 'ro': {'exact_match': 57.64705882352941, 'f1': 71.08178076607291},\n"," 'th': {'exact_match': 35.04201680672269, 'f1': 42.62885154061629}}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"markdown","metadata":{},"source":["#### Results for Adapter after 4 Epochs of training"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["{'en': {'exact_match': 70.67226890756302, 'f1': 82.5247970156043},\n"," 'es': {'exact_match': 55.04201680672269, 'f1': 73.57229446436855},\n"," 'de': {'exact_match': 56.30252100840336, 'f1': 71.14567157643546},\n"," 'el': {'exact_match': 43.109243697478995, 'f1': 56.378219636212144},\n"," 'ru': {'exact_match': 52.52100840336134, 'f1': 68.55032134571113},\n"," 'tr': {'exact_match': 36.134453781512605, 'f1': 52.10511404616692},\n"," 'ar': {'exact_match': 43.69747899159664, 'f1': 60.071794671501856},\n"," 'vi': {'exact_match': 47.64705882352941, 'f1': 68.2884260182452},\n"," 'zh': {'exact_match': 47.64705882352941, 'f1': 56.072629051620595},\n"," 'hi': {'exact_match': 40.08403361344538, 'f1': 53.37206132647197},\n"," 'ro': {'exact_match': 57.64705882352941, 'f1': 71.08178076607291},\n"," 'th': {'exact_match': 35.04201680672269, 'f1': 42.62885154061629}}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"markdown","metadata":{},"source":["#### Results for Adapter after 2 Epochs of training"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T20:34:04.860626Z","iopub.status.busy":"2022-06-11T20:34:04.860267Z","iopub.status.idle":"2022-06-11T20:34:04.866766Z","shell.execute_reply":"2022-06-11T20:34:04.865637Z","shell.execute_reply.started":"2022-06-11T20:34:04.860593Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'en': {'exact_match': 69.07563025210084, 'f1': 80.99319834889582},\n"," 'es': {'exact_match': 54.78991596638655, 'f1': 72.82869266842113},\n"," 'de': {'exact_match': 53.78151260504202, 'f1': 69.47479459163338},\n"," 'el': {'exact_match': 43.109243697478995, 'f1': 56.37360689448754},\n"," 'ru': {'exact_match': 52.10084033613445, 'f1': 67.37157635980115},\n"," 'tr': {'exact_match': 34.78991596638655, 'f1': 50.36518862309762},\n"," 'ar': {'exact_match': 43.36134453781513, 'f1': 59.31706160923957},\n"," 'vi': {'exact_match': 47.47899159663866, 'f1': 67.62077693115245},\n"," 'zh': {'exact_match': 47.226890756302524, 'f1': 55.9277711084433},\n"," 'hi': {'exact_match': 38.65546218487395, 'f1': 52.36370796776133},\n"," 'ro': {'exact_match': 56.80672268907563, 'f1': 70.42534043163606},\n"," 'th': {'exact_match': 36.470588235294116, 'f1': 43.673269307723125}}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('aml')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"cbc899a97c8cc5998e86f9df52bd5ee7235fa023cb0251f74c37f5d7e8be5c3a"}}},"nbformat":4,"nbformat_minor":4}
