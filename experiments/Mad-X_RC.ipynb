{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating XLM Roberta Base in MAD-X setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'squad_adapter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers.adapters.composition as ac\n",
    "import transformers.adapters.configuration as cf\n",
    "\n",
    "adapter_checkpoint = \"./adapter_qa_xlm_4ep/\"\n",
    "adapter_name = 'squad_adapter'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model.load_adapter(adapter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(dataset):\n",
    "    \n",
    "    predictions = []\n",
    "    for example in tqdm(dataset):\n",
    "        question = example['question']\n",
    "        context = example['context']\n",
    "        prediction = question_answerer(question=question, context=context)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert the variables so that they can be used by the evaluation.compute function\n",
    "def convert_for_evaluation(predictions, examples):\n",
    "    ref = []\n",
    "    pred = []\n",
    "    for i, id in enumerate(examples['id']):\n",
    "        ref.append({\n",
    "            'answers': examples['answers'][i],\n",
    "            'id': examples['id'][i]\n",
    "        })\n",
    "        pred.append({\n",
    "            'prediction_text': predictions[i]['answer'],\n",
    "            'id': examples['id'][i]\n",
    "        })\n",
    "        \n",
    "    return pred, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.en/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 349.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 400/1190 [01:30<05:15,  2.51it/s]/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:708: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "100%|██████████| 1190/1190 [05:41<00:00,  3.48it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 573.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:02<00:00,  3.28it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.de/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [05:59<00:00,  3.31it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.el/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 181.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:47<00:00,  2.55it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:34<00:00,  3.01it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.tr/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [05:34<00:00,  3.56it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 690.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:16<00:00,  3.16it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.vi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for vi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:20<00:00,  3.12it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.zh/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 247.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [05:25<00:00,  3.66it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.hi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 201.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:10<00:00,  2.76it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ro/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:06<00:00,  3.24it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:00<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "results = {}\n",
    "\n",
    "languages = [\"en\", \"es\", \"de\", \"el\", \"ru\", \"tr\", \"ar\", \"vi\", \"zh\", \"hi\", \"ro\", \"th\"]\n",
    "for lang in languages:\n",
    "    config = cf.AdapterConfig.load(\"pfeiffer\", non_linearity=\"relu\", reduction_factor=2)\n",
    "    model.load_adapter(\n",
    "        'en/wiki@ukp',\n",
    "        config='pfeiffer',\n",
    "        model_name='xlm-roberta-base',\n",
    "        load_as=f'{lang}/wiki@ukp',\n",
    "        source='ah'\n",
    "    )\n",
    "    model.active_adapters = ac.Stack(adapter_name, f\"{lang}/wiki@ukp\")\n",
    "    dataset = load_dataset(\"xquad\", 'xquad.' + lang)['validation']\n",
    "\n",
    "    question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    print('Running predictions for', lang)\n",
    "    predictions = get_predictions(dataset)\n",
    "\n",
    "    predictions, references = convert_for_evaluation(predictions, dataset) \n",
    "    res = squad_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    results[lang] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'exact_match': 70.0, 'f1': 81.3260141492324},\n",
       " 'es': {'exact_match': 55.04201680672269, 'f1': 73.43141574034739},\n",
       " 'de': {'exact_match': 56.05042016806723, 'f1': 71.65397632156589},\n",
       " 'el': {'exact_match': 52.60504201680672, 'f1': 69.2665514387606},\n",
       " 'ru': {'exact_match': 55.79831932773109, 'f1': 72.17426785928329},\n",
       " 'tr': {'exact_match': 50.252100840336134, 'f1': 66.15281654731778},\n",
       " 'ar': {'exact_match': 38.99159663865546, 'f1': 57.27048573125125},\n",
       " 'vi': {'exact_match': 51.34453781512605, 'f1': 71.26370816260918},\n",
       " 'zh': {'exact_match': 43.02521008403362, 'f1': 51.89612208519768},\n",
       " 'hi': {'exact_match': 47.563025210084035, 'f1': 64.48767852602755},\n",
       " 'ro': {'exact_match': 60.588235294117645, 'f1': 74.63924105396464},\n",
       " 'th': {'exact_match': 55.79831932773109, 'f1': 65.65526210484187}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating mBERT Base in MAD-X setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'squad_adapter'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers.adapters.composition as ac\n",
    "import transformers.adapters.configuration as cf\n",
    "\n",
    "adapter_checkpoint = \"./adapter_qa_4ep/\"\n",
    "adapter_name = 'squad_adapter'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model.load_adapter(adapter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 24.2kB [00:00, 9.40MB/s]                   \n",
      "Downloading: 100%|██████████| 28.2M/28.2M [00:07<00:00, 4.18MB/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.en/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 471.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 400/1190 [01:25<04:16,  3.08it/s]/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:708: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/mmm/anaconda3/envs/aml/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "100%|██████████| 1190/1190 [05:09<00:00,  3.85it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 527.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:00<00:00,  3.30it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.de/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 601.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [05:59<00:00,  3.31it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.el/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 753.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [12:49<00:00,  1.55it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 594.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:45<00:00,  2.56it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.tr/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 553.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:29<00:00,  2.65it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 781.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [08:16<00:00,  2.40it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.vi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 464.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for vi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [06:19<00:00,  3.14it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.zh/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 506.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:01<00:00,  2.83it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.hi/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 693.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [09:33<00:00,  2.08it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.ro/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 366.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for ro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [07:46<00:00,  2.55it/s]\n",
      "Reusing dataset xquad (/home/mmm/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 727.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [18:06<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "results = {}\n",
    "\n",
    "languages = [\"en\", \"es\", \"de\", \"el\", \"ru\", \"tr\", \"ar\", \"vi\", \"zh\", \"hi\", \"ro\", \"th\"]\n",
    "for lang in languages:\n",
    "    config = cf.AdapterConfig.load(\"pfeiffer\", non_linearity=\"relu\", reduction_factor=2)\n",
    "    model.load_adapter(\n",
    "        'en/wiki@ukp',\n",
    "        config='pfeiffer',\n",
    "        model_name=model_checkpoint,\n",
    "        load_as=f'{lang}/wiki@ukp',\n",
    "        source='ah'\n",
    "    )\n",
    "    model.active_adapters = ac.Stack(adapter_name, f\"{lang}/wiki@ukp\")\n",
    "    dataset = load_dataset(\"xquad\", 'xquad.' + lang)['validation']\n",
    "\n",
    "    question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    print('Running predictions for', lang)\n",
    "    predictions = get_predictions(dataset)\n",
    "\n",
    "    predictions, references = convert_for_evaluation(predictions, dataset) \n",
    "    res = squad_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    results[lang] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': {'exact_match': 70.92436974789916, 'f1': 82.46243639739903},\n",
       " 'es': {'exact_match': 53.69747899159664, 'f1': 71.03978105417272},\n",
       " 'de': {'exact_match': 53.78151260504202, 'f1': 68.61935031500029},\n",
       " 'el': {'exact_match': 39.91596638655462, 'f1': 53.18143870056999},\n",
       " 'ru': {'exact_match': 48.57142857142857, 'f1': 64.97603221042606},\n",
       " 'tr': {'exact_match': 31.26050420168067, 'f1': 46.06795492089609},\n",
       " 'ar': {'exact_match': 37.142857142857146, 'f1': 52.78504211048965},\n",
       " 'vi': {'exact_match': 44.53781512605042, 'f1': 64.33508909038494},\n",
       " 'zh': {'exact_match': 43.529411764705884, 'f1': 51.46198479391753},\n",
       " 'hi': {'exact_match': 34.03361344537815, 'f1': 47.129948699019785},\n",
       " 'ro': {'exact_match': 53.445378151260506, 'f1': 67.37462869784147},\n",
       " 'th': {'exact_match': 25.630252100840337, 'f1': 31.068760837668403}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbc899a97c8cc5998e86f9df52bd5ee7235fa023cb0251f74c37f5d7e8be5c3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
